{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1RvuuWvcSnDzrvqufWXDO1lqEx4N1ky1a",
      "authorship_tag": "ABX9TyPGbwIkw5hqAsvhRWJXSISF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tesfayeaddis1/AI-ANN-Model/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ni0R3-vOy8GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wiRPslNxr7km"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/New folder/data.csv')\n",
        "data = data.reindex(np.random.permutation(data.index))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"price\"] = np.log((data.price + 1)) "
      ],
      "metadata": {
        "id": "qv3AXzhMzeEY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.corr())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZGWC5xjzCeO",
        "outputId": "eb8b6efa-d6b9-4b1c-f64f-21c4be586f64"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  price  bedrooms  bathrooms  sqft_living  sqft_lot    floors  \\\n",
            "price          1.000000  0.070052   0.135704     0.182691  0.027662  0.115600   \n",
            "bedrooms       0.070052  1.000000   0.545920     0.594884  0.068819  0.177895   \n",
            "bathrooms      0.135704  0.545920   1.000000     0.761154  0.107837  0.486428   \n",
            "sqft_living    0.182691  0.594884   0.761154     1.000000  0.210538  0.344850   \n",
            "sqft_lot       0.027662  0.068819   0.107837     0.210538  1.000000  0.003750   \n",
            "floors         0.115600  0.177895   0.486428     0.344850  0.003750  1.000000   \n",
            "waterfront    -0.011130 -0.003483   0.076232     0.117616  0.017241  0.022024   \n",
            "view           0.049657  0.111028   0.211960     0.311009  0.073907  0.031211   \n",
            "condition     -0.009580  0.025080  -0.119994    -0.062826  0.000558 -0.275013   \n",
            "sqft_above     0.161910  0.484705   0.689918     0.876443  0.216455  0.522814   \n",
            "sqft_basement  0.078372  0.334165   0.298020     0.447206  0.034842 -0.255510   \n",
            "yr_built       0.024780  0.142461   0.463498     0.287775  0.050706  0.467481   \n",
            "yr_renovated  -0.023865 -0.061082  -0.215886    -0.122817 -0.022730 -0.233996   \n",
            "\n",
            "               waterfront      view  condition  sqft_above  sqft_basement  \\\n",
            "price           -0.011130  0.049657  -0.009580    0.161910       0.078372   \n",
            "bedrooms        -0.003483  0.111028   0.025080    0.484705       0.334165   \n",
            "bathrooms        0.076232  0.211960  -0.119994    0.689918       0.298020   \n",
            "sqft_living      0.117616  0.311009  -0.062826    0.876443       0.447206   \n",
            "sqft_lot         0.017241  0.073907   0.000558    0.216455       0.034842   \n",
            "floors           0.022024  0.031211  -0.275013    0.522814      -0.255510   \n",
            "waterfront       1.000000  0.360935   0.000352    0.078911       0.097501   \n",
            "view             0.360935  1.000000   0.063077    0.174327       0.321602   \n",
            "condition        0.000352  0.063077   1.000000   -0.178196       0.200632   \n",
            "sqft_above       0.078911  0.174327  -0.178196    1.000000      -0.038723   \n",
            "sqft_basement    0.097501  0.321602   0.200632   -0.038723       1.000000   \n",
            "yr_built        -0.023563 -0.064465  -0.399698    0.408535      -0.161675   \n",
            "yr_renovated     0.008625  0.022967  -0.186818   -0.160426       0.043125   \n",
            "\n",
            "               yr_built  yr_renovated  \n",
            "price          0.024780     -0.023865  \n",
            "bedrooms       0.142461     -0.061082  \n",
            "bathrooms      0.463498     -0.215886  \n",
            "sqft_living    0.287775     -0.122817  \n",
            "sqft_lot       0.050706     -0.022730  \n",
            "floors         0.467481     -0.233996  \n",
            "waterfront    -0.023563      0.008625  \n",
            "view          -0.064465      0.022967  \n",
            "condition     -0.399698     -0.186818  \n",
            "sqft_above     0.408535     -0.160426  \n",
            "sqft_basement -0.161675      0.043125  \n",
            "yr_built       1.000000     -0.321342  \n",
            "yr_renovated  -0.321342      1.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = data.iloc[:3910]\n",
        "test = data.iloc[3910:,:]"
      ],
      "metadata": {
        "id": "TmuPRlqB0Qzc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featureColumns = []\n",
        "bedrooms = tf.feature_column.numeric_column(\"bedrooms\")\n",
        "featureColumns.append(bedrooms)\n",
        "\n",
        "bathrooms = tf.feature_column.numeric_column(\"bathrooms\")\n",
        "featureColumns.append(bathrooms)\n",
        "\n",
        "sqft_living = tf.feature_column.numeric_column(\"sqft_living\")\n",
        "featureColumns.append(sqft_living)\n",
        "\n",
        "floors = tf.feature_column.numeric_column(\"floors\")\n",
        "featureColumns.append(floors)\n",
        "\n",
        "waterfront = tf.feature_column.numeric_column(\"waterfront\")\n",
        "featureColumns.append(waterfront)\n",
        "\n",
        "view = tf.feature_column.numeric_column(\"view\")\n",
        "featureColumns.append(view)\n",
        "\n",
        "condition = tf.feature_column.numeric_column(\"condition\")\n",
        "featureColumns.append(condition)\n",
        "\n",
        "featureLayer = tf.keras.layers.DenseFeatures(featureColumns)"
      ],
      "metadata": {
        "id": "-sLwwcXx0qMC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def buildModel(my_learningRate, my_featureLayer):\n",
        "    model = tf.keras.models.Sequential() #creating a sequential model\n",
        "    model.add(my_featureLayer) #adding the feature layer\n",
        "    model.add(tf.keras.layers.Dense(units=60,activation='relu', name=\"1st_Hidden_Layer\",    #adding the first hidden layer. 30 nodes\n",
        "                                    kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                    bias_regularizer=regularizers.L2(1e-4),\n",
        "                                    activity_regularizer=regularizers.L2(1e-5))) \n",
        "    model.add(tf.keras.layers.Dense(units=30, activation='relu', name=\"2nd_Hidden_Layer\",    #adding the second hidden layer. 30 nodes\n",
        "                                    kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                    bias_regularizer=regularizers.L2(1e-4),\n",
        "                                    activity_regularizer=regularizers.L2(1e-5)))\n",
        "    model.add(tf.keras.layers.Dense(units=1, name='Output_Layer',                           #adding the output layer\n",
        "                                    kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                    bias_regularizer=regularizers.L2(1e-4),\n",
        "                                    activity_regularizer=regularizers.L2(1e-5)))\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learningRate), #compiling the model and using mean squared error for loss\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.MeanSquaredError()])\n",
        "    return model "
      ],
      "metadata": {
        "id": "oRW17PzK4h_8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainModel(model, dataset, epochs, label_name, batch_size=None, validationSplit=0.2):\n",
        "\n",
        "  features = {name:np.array(value) for name, value in dataset.items()} #splitting the dataset into features and label\n",
        "  label = np.array(features.pop(label_name))\n",
        "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
        "                      epochs=epochs, shuffle=True, validation_split=validationSplit) \n",
        "  epochs = history.epoch\n",
        "  hist = pd.DataFrame(history.history) #getting the mse at each epoch\n",
        "  mse = hist[\"mean_squared_error\"]\n",
        "\n",
        "  return epochs, mse  "
      ],
      "metadata": {
        "id": "Yrr0snho3odS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_the_loss_curve(epochs, mse):\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Mean Squared Error\")\n",
        "  plt.plot(epochs, mse, label=\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.ylim([mse.min()*0.95, mse.max() * 1.05])\n",
        "  plt.show()  "
      ],
      "metadata": {
        "id": "wisUSr8r33ZI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.011\n",
        "epochs = 250\n",
        "batch_size = 100\n",
        "validation_split = .2\n",
        "\n",
        "#label name\n",
        "label_name = \"price\""
      ],
      "metadata": {
        "id": "vunMTuvb3-Dr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myModel = buildModel(learning_rate, featureLayer)\n",
        "\n",
        "#training the model on the train dataframe\n",
        "epochs, rmse = trainModel(myModel, train, epochs, label_name, batch_size)\n",
        "plot_the_loss_curve(epochs, rmse)\n",
        "\n",
        "#testing the model against the test dataframe\n",
        "testFeatures = {name:np.array(value) for name, value in test.items()}\n",
        "testLabel = np.array(testFeatures.pop(label_name))\n",
        "myModel.evaluate(x = testFeatures, y = testLabel, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4i25WCuW45hu",
        "outputId": "d0b71d39-fa58-4959-bcf9-237abc6e9aa2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'date': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>, 'bedrooms': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'bathrooms': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float32>, 'sqft_living': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=int64>, 'sqft_lot': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=int64>, 'floors': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'waterfront': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=int64>, 'view': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=int64>, 'condition': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=int64>, 'sqft_above': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=int64>, 'sqft_basement': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=int64>, 'yr_built': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=int64>, 'yr_renovated': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=int64>, 'street': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=string>, 'city': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'statezip': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=string>, 'country': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'date': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>, 'bedrooms': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'bathrooms': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float32>, 'sqft_living': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=int64>, 'sqft_lot': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=int64>, 'floors': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'waterfront': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=int64>, 'view': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=int64>, 'condition': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=int64>, 'sqft_above': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=int64>, 'sqft_basement': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=int64>, 'yr_built': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=int64>, 'yr_renovated': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=int64>, 'street': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=string>, 'city': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'statezip': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=string>, 'country': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/32 [======================>.......] - ETA: 0s - loss: 19313.5059 - mean_squared_error: 19249.9766"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'date': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>, 'bedrooms': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'bathrooms': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float32>, 'sqft_living': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=int64>, 'sqft_lot': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=int64>, 'floors': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'waterfront': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=int64>, 'view': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=int64>, 'condition': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=int64>, 'sqft_above': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=int64>, 'sqft_basement': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=int64>, 'yr_built': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=int64>, 'yr_renovated': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=int64>, 'street': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=string>, 'city': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'statezip': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=string>, 'country': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 2s 17ms/step - loss: 15473.2754 - mean_squared_error: 15409.2285 - val_loss: 167.0491 - val_mean_squared_error: 102.9988\n",
            "Epoch 2/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 100.1332 - mean_squared_error: 38.1392 - val_loss: 103.7134 - val_mean_squared_error: 40.6287\n",
            "Epoch 3/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 97.5128 - mean_squared_error: 36.7574 - val_loss: 100.7590 - val_mean_squared_error: 39.2144\n",
            "Epoch 4/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 90.7228 - mean_squared_error: 31.3623 - val_loss: 92.3970 - val_mean_squared_error: 31.9790\n",
            "Epoch 5/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 88.0282 - mean_squared_error: 29.6536 - val_loss: 92.1089 - val_mean_squared_error: 32.5418\n",
            "Epoch 6/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 86.5593 - mean_squared_error: 29.0448 - val_loss: 94.3824 - val_mean_squared_error: 35.6197\n",
            "Epoch 7/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 86.2915 - mean_squared_error: 29.5472 - val_loss: 86.6685 - val_mean_squared_error: 28.7621\n",
            "Epoch 8/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 85.0330 - mean_squared_error: 29.0108 - val_loss: 87.4124 - val_mean_squared_error: 30.2480\n",
            "Epoch 9/250\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 82.7790 - mean_squared_error: 27.4490 - val_loss: 89.1521 - val_mean_squared_error: 32.7169\n",
            "Epoch 10/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 78.4787 - mean_squared_error: 23.8388 - val_loss: 82.4948 - val_mean_squared_error: 26.6670\n",
            "Epoch 11/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 77.0795 - mean_squared_error: 23.1037 - val_loss: 91.8015 - val_mean_squared_error: 36.6004\n",
            "Epoch 12/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 77.4555 - mean_squared_error: 24.1493 - val_loss: 76.8512 - val_mean_squared_error: 22.4366\n",
            "Epoch 13/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 76.8890 - mean_squared_error: 24.2731 - val_loss: 97.7433 - val_mean_squared_error: 43.9530\n",
            "Epoch 14/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 72.2922 - mean_squared_error: 20.3611 - val_loss: 74.3634 - val_mean_squared_error: 21.3618\n",
            "Epoch 15/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 71.4615 - mean_squared_error: 20.1881 - val_loss: 71.3690 - val_mean_squared_error: 19.0293\n",
            "Epoch 16/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 68.5234 - mean_squared_error: 17.9040 - val_loss: 70.8937 - val_mean_squared_error: 19.2321\n",
            "Epoch 17/250\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 67.9542 - mean_squared_error: 17.9766 - val_loss: 68.3149 - val_mean_squared_error: 17.2897\n",
            "Epoch 18/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 69.4608 - mean_squared_error: 20.1499 - val_loss: 67.0828 - val_mean_squared_error: 16.7712\n",
            "Epoch 19/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 63.7239 - mean_squared_error: 15.0823 - val_loss: 68.4291 - val_mean_squared_error: 18.7896\n",
            "Epoch 20/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 62.3923 - mean_squared_error: 14.3889 - val_loss: 62.9651 - val_mean_squared_error: 13.9825\n",
            "Epoch 21/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 60.2263 - mean_squared_error: 12.8538 - val_loss: 62.2939 - val_mean_squared_error: 13.9478\n",
            "Epoch 22/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 64.4576 - mean_squared_error: 17.7073 - val_loss: 83.5987 - val_mean_squared_error: 35.9344\n",
            "Epoch 23/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 65.7175 - mean_squared_error: 19.6620 - val_loss: 70.7388 - val_mean_squared_error: 23.7664\n",
            "Epoch 24/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 58.2962 - mean_squared_error: 12.9148 - val_loss: 56.9302 - val_mean_squared_error: 10.6351\n",
            "Epoch 25/250\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 54.1528 - mean_squared_error: 9.3910 - val_loss: 55.1658 - val_mean_squared_error: 9.4845\n",
            "Epoch 26/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 53.2611 - mean_squared_error: 9.0926 - val_loss: 53.7928 - val_mean_squared_error: 8.7192\n",
            "Epoch 27/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 52.9434 - mean_squared_error: 9.3629 - val_loss: 52.7283 - val_mean_squared_error: 8.2659\n",
            "Epoch 28/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 50.1954 - mean_squared_error: 7.2077 - val_loss: 51.2617 - val_mean_squared_error: 7.3919\n",
            "Epoch 29/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 54.2456 - mean_squared_error: 11.8478 - val_loss: 56.3243 - val_mean_squared_error: 13.0816\n",
            "Epoch 30/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 48.1381 - mean_squared_error: 6.3415 - val_loss: 51.3708 - val_mean_squared_error: 8.7310\n",
            "Epoch 31/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 47.8565 - mean_squared_error: 6.6304 - val_loss: 47.9931 - val_mean_squared_error: 5.9354\n",
            "Epoch 32/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 47.6550 - mean_squared_error: 7.0016 - val_loss: 48.7427 - val_mean_squared_error: 7.2687\n",
            "Epoch 33/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 47.4701 - mean_squared_error: 7.3814 - val_loss: 50.3297 - val_mean_squared_error: 9.4386\n",
            "Epoch 34/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 45.9348 - mean_squared_error: 6.4146 - val_loss: 47.1524 - val_mean_squared_error: 6.8403\n",
            "Epoch 35/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 46.3782 - mean_squared_error: 7.4106 - val_loss: 46.0848 - val_mean_squared_error: 6.3484\n",
            "Epoch 36/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 44.2197 - mean_squared_error: 5.8142 - val_loss: 44.8321 - val_mean_squared_error: 5.6567\n",
            "Epoch 37/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 43.3620 - mean_squared_error: 5.4962 - val_loss: 43.6955 - val_mean_squared_error: 5.0752\n",
            "Epoch 38/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 42.1342 - mean_squared_error: 4.8058 - val_loss: 43.6375 - val_mean_squared_error: 5.5594\n",
            "Epoch 39/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 41.5741 - mean_squared_error: 4.7729 - val_loss: 46.2996 - val_mean_squared_error: 8.7689\n",
            "Epoch 40/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 41.7940 - mean_squared_error: 5.5201 - val_loss: 41.2372 - val_mean_squared_error: 4.2396\n",
            "Epoch 41/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 39.7647 - mean_squared_error: 4.0059 - val_loss: 41.1659 - val_mean_squared_error: 4.6937\n",
            "Epoch 42/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 39.0805 - mean_squared_error: 3.8291 - val_loss: 39.9482 - val_mean_squared_error: 3.9895\n",
            "Epoch 43/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 38.6026 - mean_squared_error: 3.8519 - val_loss: 39.3838 - val_mean_squared_error: 3.9478\n",
            "Epoch 44/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 38.0812 - mean_squared_error: 3.8307 - val_loss: 47.6386 - val_mean_squared_error: 12.6964\n",
            "Epoch 45/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 39.1783 - mean_squared_error: 5.4259 - val_loss: 38.3509 - val_mean_squared_error: 3.9413\n",
            "Epoch 46/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 37.1457 - mean_squared_error: 3.8914 - val_loss: 40.1680 - val_mean_squared_error: 6.2578\n",
            "Epoch 47/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 37.8362 - mean_squared_error: 5.0634 - val_loss: 37.5856 - val_mean_squared_error: 4.1679\n",
            "Epoch 48/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 39.2356 - mean_squared_error: 6.9618 - val_loss: 39.5434 - val_mean_squared_error: 6.6454\n",
            "Epoch 49/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 36.1230 - mean_squared_error: 4.3343 - val_loss: 36.6241 - val_mean_squared_error: 4.2085\n",
            "Epoch 50/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 35.5974 - mean_squared_error: 4.2706 - val_loss: 36.1611 - val_mean_squared_error: 4.2210\n",
            "Epoch 51/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 34.8297 - mean_squared_error: 3.9628 - val_loss: 38.9402 - val_mean_squared_error: 7.4669\n",
            "Epoch 52/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 34.4526 - mean_squared_error: 4.0412 - val_loss: 36.5769 - val_mean_squared_error: 5.5624\n",
            "Epoch 53/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 33.6030 - mean_squared_error: 3.6389 - val_loss: 34.8140 - val_mean_squared_error: 4.2585\n",
            "Epoch 54/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 33.9333 - mean_squared_error: 4.4150 - val_loss: 34.1383 - val_mean_squared_error: 4.0509\n",
            "Epoch 55/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 33.1610 - mean_squared_error: 4.0988 - val_loss: 34.9746 - val_mean_squared_error: 5.3442\n",
            "Epoch 56/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 32.0472 - mean_squared_error: 3.4244 - val_loss: 33.0602 - val_mean_squared_error: 3.8829\n",
            "Epoch 57/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 32.0163 - mean_squared_error: 3.8336 - val_loss: 36.3692 - val_mean_squared_error: 7.6357\n",
            "Epoch 58/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 31.5086 - mean_squared_error: 3.7605 - val_loss: 32.7288 - val_mean_squared_error: 4.4468\n",
            "Epoch 59/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 32.6536 - mean_squared_error: 5.3425 - val_loss: 32.6554 - val_mean_squared_error: 4.8307\n",
            "Epoch 60/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 32.4253 - mean_squared_error: 5.5578 - val_loss: 32.4977 - val_mean_squared_error: 5.1282\n",
            "Epoch 61/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 29.8852 - mean_squared_error: 3.4563 - val_loss: 30.7951 - val_mean_squared_error: 3.8614\n",
            "Epoch 62/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 29.1696 - mean_squared_error: 3.1542 - val_loss: 30.5919 - val_mean_squared_error: 4.0763\n",
            "Epoch 63/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 29.3709 - mean_squared_error: 3.7662 - val_loss: 29.7940 - val_mean_squared_error: 3.7024\n",
            "Epoch 64/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 29.1405 - mean_squared_error: 3.9470 - val_loss: 29.5472 - val_mean_squared_error: 3.8797\n",
            "Epoch 65/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 28.0568 - mean_squared_error: 3.2711 - val_loss: 29.1386 - val_mean_squared_error: 3.8857\n",
            "Epoch 66/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 27.7527 - mean_squared_error: 3.3696 - val_loss: 29.0039 - val_mean_squared_error: 4.1591\n",
            "Epoch 67/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 28.8084 - mean_squared_error: 4.8292 - val_loss: 28.0569 - val_mean_squared_error: 3.6430\n",
            "Epoch 68/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 27.0135 - mean_squared_error: 3.4480 - val_loss: 27.6512 - val_mean_squared_error: 3.6434\n",
            "Epoch 69/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 26.7943 - mean_squared_error: 3.6282 - val_loss: 27.3708 - val_mean_squared_error: 3.7773\n",
            "Epoch 70/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 26.2947 - mean_squared_error: 3.5290 - val_loss: 28.3379 - val_mean_squared_error: 5.1516\n",
            "Epoch 71/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 25.6845 - mean_squared_error: 3.3098 - val_loss: 26.4051 - val_mean_squared_error: 3.6211\n",
            "Epoch 72/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 25.2461 - mean_squared_error: 3.2576 - val_loss: 27.2445 - val_mean_squared_error: 4.8535\n",
            "Epoch 73/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 25.4114 - mean_squared_error: 3.8081 - val_loss: 26.6420 - val_mean_squared_error: 4.6574\n",
            "Epoch 74/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 25.3787 - mean_squared_error: 4.1695 - val_loss: 26.3243 - val_mean_squared_error: 4.7403\n",
            "Epoch 75/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 24.0924 - mean_squared_error: 3.2694 - val_loss: 27.5231 - val_mean_squared_error: 6.3211\n",
            "Epoch 76/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 24.7465 - mean_squared_error: 4.3006 - val_loss: 24.4732 - val_mean_squared_error: 3.6731\n",
            "Epoch 77/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 23.7216 - mean_squared_error: 3.6642 - val_loss: 24.1537 - val_mean_squared_error: 3.7433\n",
            "Epoch 78/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 23.2734 - mean_squared_error: 3.5897 - val_loss: 24.2032 - val_mean_squared_error: 4.1774\n",
            "Epoch 79/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 22.7108 - mean_squared_error: 3.4003 - val_loss: 23.7767 - val_mean_squared_error: 4.1280\n",
            "Epoch 80/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 22.2442 - mean_squared_error: 3.2994 - val_loss: 22.9239 - val_mean_squared_error: 3.6513\n",
            "Epoch 81/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 21.6135 - mean_squared_error: 3.0302 - val_loss: 22.4201 - val_mean_squared_error: 3.5170\n",
            "Epoch 82/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 21.9183 - mean_squared_error: 3.6954 - val_loss: 26.0234 - val_mean_squared_error: 7.4884\n",
            "Epoch 83/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 22.0161 - mean_squared_error: 4.1628 - val_loss: 21.6740 - val_mean_squared_error: 3.5255\n",
            "Epoch 84/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 21.0946 - mean_squared_error: 3.6048 - val_loss: 21.3497 - val_mean_squared_error: 3.5687\n",
            "Epoch 85/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 20.4401 - mean_squared_error: 3.3082 - val_loss: 22.0907 - val_mean_squared_error: 4.6744\n",
            "Epoch 86/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 20.0108 - mean_squared_error: 3.2279 - val_loss: 23.3595 - val_mean_squared_error: 6.3067\n",
            "Epoch 87/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 20.4886 - mean_squared_error: 4.0597 - val_loss: 20.6200 - val_mean_squared_error: 3.9301\n",
            "Epoch 88/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 19.3349 - mean_squared_error: 3.2544 - val_loss: 20.0489 - val_mean_squared_error: 3.7059\n",
            "Epoch 89/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 18.7756 - mean_squared_error: 3.0302 - val_loss: 20.3471 - val_mean_squared_error: 4.3478\n",
            "Epoch 90/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 18.8662 - mean_squared_error: 3.4569 - val_loss: 25.9366 - val_mean_squared_error: 10.2912\n",
            "Epoch 91/250\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 19.0319 - mean_squared_error: 3.9641 - val_loss: 18.9010 - val_mean_squared_error: 3.5969\n",
            "Epoch 92/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 18.0047 - mean_squared_error: 3.2690 - val_loss: 18.8589 - val_mean_squared_error: 3.8925\n",
            "Epoch 93/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 17.6567 - mean_squared_error: 3.2462 - val_loss: 18.0888 - val_mean_squared_error: 3.4540\n",
            "Epoch 94/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 17.5485 - mean_squared_error: 3.4628 - val_loss: 17.7995 - val_mean_squared_error: 3.5017\n",
            "Epoch 95/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 16.7762 - mean_squared_error: 3.0134 - val_loss: 17.6417 - val_mean_squared_error: 3.6698\n",
            "Epoch 96/250\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 16.5046 - mean_squared_error: 3.0596 - val_loss: 17.3327 - val_mean_squared_error: 3.6857\n",
            "Epoch 97/250\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 16.0223 - mean_squared_error: 2.8927 - val_loss: 17.1743 - val_mean_squared_error: 3.8451\n",
            "Epoch 98/250\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 15.8897 - mean_squared_error: 3.0674 - val_loss: 17.1804 - val_mean_squared_error: 4.1643\n",
            "Epoch 99/250\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 15.8309 - mean_squared_error: 3.3150 - val_loss: 16.2710 - val_mean_squared_error: 3.5710\n",
            "Epoch 100/250\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 15.2351 - mean_squared_error: 3.0228 - val_loss: 17.1096 - val_mean_squared_error: 4.7275\n",
            "Epoch 101/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 16.2858 - mean_squared_error: 4.3782 - val_loss: 24.5931 - val_mean_squared_error: 12.5126\n",
            "Epoch 102/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 16.2378 - mean_squared_error: 4.6436 - val_loss: 20.8798 - val_mean_squared_error: 9.1231\n",
            "Epoch 103/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 16.2216 - mean_squared_error: 4.9366 - val_loss: 16.9604 - val_mean_squared_error: 5.5220\n",
            "Epoch 104/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 14.6004 - mean_squared_error: 3.6237 - val_loss: 15.5769 - val_mean_squared_error: 4.4523\n",
            "Epoch 105/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 13.8401 - mean_squared_error: 3.1470 - val_loss: 14.3970 - val_mean_squared_error: 3.5574\n",
            "Epoch 106/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 13.4662 - mean_squared_error: 3.0505 - val_loss: 14.0551 - val_mean_squared_error: 3.4992\n",
            "Epoch 107/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 13.1508 - mean_squared_error: 3.0082 - val_loss: 13.9549 - val_mean_squared_error: 3.6761\n",
            "Epoch 108/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 12.6905 - mean_squared_error: 2.8179 - val_loss: 13.3470 - val_mean_squared_error: 3.3422\n",
            "Epoch 109/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 13.7027 - mean_squared_error: 4.0947 - val_loss: 17.9848 - val_mean_squared_error: 8.2637\n",
            "Epoch 110/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 13.7316 - mean_squared_error: 4.4071 - val_loss: 20.5070 - val_mean_squared_error: 11.0757\n",
            "Epoch 111/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 14.4097 - mean_squared_error: 5.3600 - val_loss: 16.2563 - val_mean_squared_error: 7.1028\n",
            "Epoch 112/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 11.6976 - mean_squared_error: 2.9200 - val_loss: 12.2348 - val_mean_squared_error: 3.3488\n",
            "Epoch 113/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 11.4705 - mean_squared_error: 2.9417 - val_loss: 14.4794 - val_mean_squared_error: 5.8542\n",
            "Epoch 114/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 11.4505 - mean_squared_error: 3.1683 - val_loss: 14.8574 - val_mean_squared_error: 6.4699\n",
            "Epoch 115/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 11.5029 - mean_squared_error: 3.4640 - val_loss: 11.5013 - val_mean_squared_error: 3.3679\n",
            "Epoch 116/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 11.0510 - mean_squared_error: 3.2494 - val_loss: 12.2647 - val_mean_squared_error: 4.3783\n",
            "Epoch 117/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 10.9821 - mean_squared_error: 3.4218 - val_loss: 10.9321 - val_mean_squared_error: 3.2917\n",
            "Epoch 118/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 10.7729 - mean_squared_error: 3.4443 - val_loss: 11.9227 - val_mean_squared_error: 4.5109\n",
            "Epoch 119/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 10.5353 - mean_squared_error: 3.4355 - val_loss: 10.6933 - val_mean_squared_error: 3.5203\n",
            "Epoch 120/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 10.2306 - mean_squared_error: 3.3577 - val_loss: 16.7340 - val_mean_squared_error: 9.7968\n",
            "Epoch 121/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 10.7732 - mean_squared_error: 4.1226 - val_loss: 10.6090 - val_mean_squared_error: 3.8930\n",
            "Epoch 122/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 10.5651 - mean_squared_error: 4.1375 - val_loss: 12.7870 - val_mean_squared_error: 6.3060\n",
            "Epoch 123/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 9.5706 - mean_squared_error: 3.3630 - val_loss: 9.4419 - val_mean_squared_error: 3.1746\n",
            "Epoch 124/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 8.6129 - mean_squared_error: 2.6058 - val_loss: 10.4329 - val_mean_squared_error: 4.3599\n",
            "Epoch 125/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 9.0149 - mean_squared_error: 3.2003 - val_loss: 9.3163 - val_mean_squared_error: 3.4470\n",
            "Epoch 126/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 8.3925 - mean_squared_error: 2.7743 - val_loss: 8.9352 - val_mean_squared_error: 3.2666\n",
            "Epoch 127/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 8.0037 - mean_squared_error: 2.5744 - val_loss: 8.7034 - val_mean_squared_error: 3.2240\n",
            "Epoch 128/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 8.2399 - mean_squared_error: 2.9939 - val_loss: 8.9197 - val_mean_squared_error: 3.6260\n",
            "Epoch 129/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 7.5112 - mean_squared_error: 2.4468 - val_loss: 8.8027 - val_mean_squared_error: 3.6962\n",
            "Epoch 130/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 7.7271 - mean_squared_error: 2.8379 - val_loss: 11.0784 - val_mean_squared_error: 6.1434\n",
            "Epoch 131/250\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 7.9737 - mean_squared_error: 3.2585 - val_loss: 11.6634 - val_mean_squared_error: 6.9056\n",
            "Epoch 132/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 7.5307 - mean_squared_error: 2.9880 - val_loss: 7.9609 - val_mean_squared_error: 3.3826\n",
            "Epoch 133/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 6.9595 - mean_squared_error: 2.5824 - val_loss: 7.5534 - val_mean_squared_error: 3.1441\n",
            "Epoch 134/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 6.6937 - mean_squared_error: 2.4764 - val_loss: 7.3472 - val_mean_squared_error: 3.0975\n",
            "Epoch 135/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 6.8333 - mean_squared_error: 2.7718 - val_loss: 7.8456 - val_mean_squared_error: 3.7522\n",
            "Epoch 136/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 6.6633 - mean_squared_error: 2.7552 - val_loss: 8.3611 - val_mean_squared_error: 4.4243\n",
            "Epoch 137/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 6.4523 - mean_squared_error: 2.6962 - val_loss: 6.9197 - val_mean_squared_error: 3.1389\n",
            "Epoch 138/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 6.0896 - mean_squared_error: 2.4788 - val_loss: 7.2409 - val_mean_squared_error: 3.6048\n",
            "Epoch 139/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 6.4200 - mean_squared_error: 2.9520 - val_loss: 7.7849 - val_mean_squared_error: 4.3020\n",
            "Epoch 140/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 6.5372 - mean_squared_error: 3.2109 - val_loss: 7.3805 - val_mean_squared_error: 4.0405\n",
            "Epoch 141/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 6.0494 - mean_squared_error: 2.8617 - val_loss: 6.4533 - val_mean_squared_error: 3.2464\n",
            "Epoch 142/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 6.0176 - mean_squared_error: 2.9597 - val_loss: 6.1957 - val_mean_squared_error: 3.1236\n",
            "Epoch 143/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 5.3652 - mean_squared_error: 2.4340 - val_loss: 6.8671 - val_mean_squared_error: 3.9231\n",
            "Epoch 144/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 5.3727 - mean_squared_error: 2.5627 - val_loss: 5.8582 - val_mean_squared_error: 3.0356\n",
            "Epoch 145/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 5.1845 - mean_squared_error: 2.4923 - val_loss: 5.6855 - val_mean_squared_error: 2.9804\n",
            "Epoch 146/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 5.2722 - mean_squared_error: 2.6934 - val_loss: 6.3758 - val_mean_squared_error: 3.7918\n",
            "Epoch 147/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 5.4489 - mean_squared_error: 2.9859 - val_loss: 6.6834 - val_mean_squared_error: 4.2091\n",
            "Epoch 148/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 5.1673 - mean_squared_error: 2.8141 - val_loss: 7.6593 - val_mean_squared_error: 5.3040\n",
            "Epoch 149/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 7.2102 - mean_squared_error: 4.9706 - val_loss: 7.8459 - val_mean_squared_error: 5.6069\n",
            "Epoch 150/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 5.9232 - mean_squared_error: 3.8038 - val_loss: 6.3196 - val_mean_squared_error: 4.1972\n",
            "Epoch 151/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 5.7614 - mean_squared_error: 3.7485 - val_loss: 6.4140 - val_mean_squared_error: 4.3997\n",
            "Epoch 152/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 4.3914 - mean_squared_error: 2.4808 - val_loss: 4.8348 - val_mean_squared_error: 2.9188\n",
            "Epoch 153/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 4.3911 - mean_squared_error: 2.5669 - val_loss: 5.0190 - val_mean_squared_error: 3.1901\n",
            "Epoch 154/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 4.7044 - mean_squared_error: 2.9680 - val_loss: 5.1627 - val_mean_squared_error: 3.4312\n",
            "Epoch 155/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 4.6707 - mean_squared_error: 3.0231 - val_loss: 4.8694 - val_mean_squared_error: 3.2208\n",
            "Epoch 156/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 3.8883 - mean_squared_error: 2.3218 - val_loss: 4.5206 - val_mean_squared_error: 2.9542\n",
            "Epoch 157/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 3.9111 - mean_squared_error: 2.4209 - val_loss: 4.4233 - val_mean_squared_error: 2.9333\n",
            "Epoch 158/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 3.9453 - mean_squared_error: 2.5303 - val_loss: 5.4280 - val_mean_squared_error: 4.0174\n",
            "Epoch 159/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 3.8787 - mean_squared_error: 2.5342 - val_loss: 4.3061 - val_mean_squared_error: 2.9641\n",
            "Epoch 160/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 3.6075 - mean_squared_error: 2.3307 - val_loss: 4.1580 - val_mean_squared_error: 2.8821\n",
            "Epoch 161/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 3.4870 - mean_squared_error: 2.2748 - val_loss: 4.3475 - val_mean_squared_error: 3.1379\n",
            "Epoch 162/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 3.9564 - mean_squared_error: 2.8086 - val_loss: 4.9945 - val_mean_squared_error: 3.8489\n",
            "Epoch 163/250\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 3.3915 - mean_squared_error: 2.3064 - val_loss: 8.7169 - val_mean_squared_error: 7.6402\n",
            "Epoch 164/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.1301 - mean_squared_error: 3.1061 - val_loss: 3.9638 - val_mean_squared_error: 2.9427\n",
            "Epoch 165/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 3.3076 - mean_squared_error: 2.3392 - val_loss: 4.6632 - val_mean_squared_error: 3.6933\n",
            "Epoch 166/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 3.2882 - mean_squared_error: 2.3718 - val_loss: 5.9533 - val_mean_squared_error: 5.0351\n",
            "Epoch 167/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 3.6531 - mean_squared_error: 2.7887 - val_loss: 3.8158 - val_mean_squared_error: 2.9576\n",
            "Epoch 168/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 3.2237 - mean_squared_error: 2.4070 - val_loss: 3.8122 - val_mean_squared_error: 2.9974\n",
            "Epoch 169/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 3.1019 - mean_squared_error: 2.3308 - val_loss: 3.6530 - val_mean_squared_error: 2.8850\n",
            "Epoch 170/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 3.3127 - mean_squared_error: 2.5859 - val_loss: 4.8319 - val_mean_squared_error: 4.1145\n",
            "Epoch 171/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 3.3284 - mean_squared_error: 2.6465 - val_loss: 4.9812 - val_mean_squared_error: 4.3001\n",
            "Epoch 172/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 3.1406 - mean_squared_error: 2.4998 - val_loss: 3.7776 - val_mean_squared_error: 3.1377\n",
            "Epoch 173/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.9570 - mean_squared_error: 2.3523 - val_loss: 4.1354 - val_mean_squared_error: 3.5366\n",
            "Epoch 174/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.9162 - mean_squared_error: 2.3464 - val_loss: 3.3708 - val_mean_squared_error: 2.8047\n",
            "Epoch 175/250\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 2.6665 - mean_squared_error: 2.1287 - val_loss: 3.5281 - val_mean_squared_error: 2.9905\n",
            "Epoch 176/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.7559 - mean_squared_error: 2.2466 - val_loss: 3.4803 - val_mean_squared_error: 2.9759\n",
            "Epoch 177/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 3.0888 - mean_squared_error: 2.6113 - val_loss: 4.2891 - val_mean_squared_error: 3.8119\n",
            "Epoch 178/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.6509 - mean_squared_error: 2.2003 - val_loss: 3.6782 - val_mean_squared_error: 3.2272\n",
            "Epoch 179/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 2.9463 - mean_squared_error: 2.5209 - val_loss: 3.6401 - val_mean_squared_error: 3.2169\n",
            "Epoch 180/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 3.0579 - mean_squared_error: 2.6608 - val_loss: 3.3698 - val_mean_squared_error: 2.9764\n",
            "Epoch 181/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.5029 - mean_squared_error: 2.1287 - val_loss: 4.7459 - val_mean_squared_error: 4.3776\n",
            "Epoch 182/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.5864 - mean_squared_error: 2.2322 - val_loss: 3.7157 - val_mean_squared_error: 3.3600\n",
            "Epoch 183/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 2.3351 - mean_squared_error: 2.0003 - val_loss: 3.0457 - val_mean_squared_error: 2.7119\n",
            "Epoch 184/250\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 2.6542 - mean_squared_error: 2.3365 - val_loss: 3.3322 - val_mean_squared_error: 3.0198\n",
            "Epoch 185/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.3726 - mean_squared_error: 2.0735 - val_loss: 3.0158 - val_mean_squared_error: 2.7181\n",
            "Epoch 186/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.5631 - mean_squared_error: 2.2797 - val_loss: 3.0431 - val_mean_squared_error: 2.7643\n",
            "Epoch 187/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.5953 - mean_squared_error: 2.3313 - val_loss: 3.4936 - val_mean_squared_error: 3.2282\n",
            "Epoch 188/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.3804 - mean_squared_error: 2.1293 - val_loss: 2.9491 - val_mean_squared_error: 2.6997\n",
            "Epoch 189/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.2114 - mean_squared_error: 1.9747 - val_loss: 2.9736 - val_mean_squared_error: 2.7384\n",
            "Epoch 190/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.3300 - mean_squared_error: 2.1034 - val_loss: 3.1512 - val_mean_squared_error: 2.9238\n",
            "Epoch 191/250\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.4524 - mean_squared_error: 2.2376 - val_loss: 2.9484 - val_mean_squared_error: 2.7360\n",
            "Epoch 192/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.3371 - mean_squared_error: 2.1325 - val_loss: 2.9464 - val_mean_squared_error: 2.7430\n",
            "Epoch 193/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.3511 - mean_squared_error: 2.1565 - val_loss: 3.0172 - val_mean_squared_error: 2.8212\n",
            "Epoch 194/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.1174 - mean_squared_error: 1.9277 - val_loss: 2.9692 - val_mean_squared_error: 2.7809\n",
            "Epoch 195/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.1495 - mean_squared_error: 1.9678 - val_loss: 2.8246 - val_mean_squared_error: 2.6436\n",
            "Epoch 196/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.2017 - mean_squared_error: 2.0283 - val_loss: 2.8242 - val_mean_squared_error: 2.6522\n",
            "Epoch 197/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 2.2279 - mean_squared_error: 2.0622 - val_loss: 2.8210 - val_mean_squared_error: 2.6563\n",
            "Epoch 198/250\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 2.0834 - mean_squared_error: 1.9246 - val_loss: 3.1039 - val_mean_squared_error: 2.9417\n",
            "Epoch 199/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.0902 - mean_squared_error: 1.9336 - val_loss: 2.8136 - val_mean_squared_error: 2.6579\n",
            "Epoch 200/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.0252 - mean_squared_error: 1.8751 - val_loss: 2.7775 - val_mean_squared_error: 2.6264\n",
            "Epoch 201/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 2.0453 - mean_squared_error: 1.8981 - val_loss: 2.7725 - val_mean_squared_error: 2.6246\n",
            "Epoch 202/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.0566 - mean_squared_error: 1.9134 - val_loss: 2.7752 - val_mean_squared_error: 2.6330\n",
            "Epoch 203/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.1496 - mean_squared_error: 2.0138 - val_loss: 2.8742 - val_mean_squared_error: 2.7376\n",
            "Epoch 204/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.0509 - mean_squared_error: 1.9176 - val_loss: 3.3155 - val_mean_squared_error: 3.1787\n",
            "Epoch 205/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.9988 - mean_squared_error: 1.8697 - val_loss: 2.9114 - val_mean_squared_error: 2.7792\n",
            "Epoch 206/250\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1.9556 - mean_squared_error: 1.8281 - val_loss: 2.8469 - val_mean_squared_error: 2.7179\n",
            "Epoch 207/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.0254 - mean_squared_error: 1.9028 - val_loss: 3.3478 - val_mean_squared_error: 3.2278\n",
            "Epoch 208/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.3738 - mean_squared_error: 2.2561 - val_loss: 3.2164 - val_mean_squared_error: 3.1044\n",
            "Epoch 209/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.1585 - mean_squared_error: 2.0439 - val_loss: 2.7099 - val_mean_squared_error: 2.5953\n",
            "Epoch 210/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.9308 - mean_squared_error: 1.8174 - val_loss: 2.8377 - val_mean_squared_error: 2.7221\n",
            "Epoch 211/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.9589 - mean_squared_error: 1.8474 - val_loss: 2.6869 - val_mean_squared_error: 2.5755\n",
            "Epoch 212/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.0107 - mean_squared_error: 1.9016 - val_loss: 2.7818 - val_mean_squared_error: 2.6718\n",
            "Epoch 213/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.9436 - mean_squared_error: 1.8380 - val_loss: 2.8272 - val_mean_squared_error: 2.7191\n",
            "Epoch 214/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.9557 - mean_squared_error: 1.8515 - val_loss: 3.0881 - val_mean_squared_error: 2.9885\n",
            "Epoch 215/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 2.2719 - mean_squared_error: 2.1742 - val_loss: 2.8739 - val_mean_squared_error: 2.7653\n",
            "Epoch 216/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.9286 - mean_squared_error: 1.8189 - val_loss: 2.8481 - val_mean_squared_error: 2.7362\n",
            "Epoch 217/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.9048 - mean_squared_error: 1.7995 - val_loss: 2.7368 - val_mean_squared_error: 2.6313\n",
            "Epoch 218/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8880 - mean_squared_error: 1.7875 - val_loss: 2.6500 - val_mean_squared_error: 2.5514\n",
            "Epoch 219/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8883 - mean_squared_error: 1.7907 - val_loss: 2.6356 - val_mean_squared_error: 2.5402\n",
            "Epoch 220/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8806 - mean_squared_error: 1.7856 - val_loss: 2.6477 - val_mean_squared_error: 2.5538\n",
            "Epoch 221/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8922 - mean_squared_error: 1.8006 - val_loss: 2.6848 - val_mean_squared_error: 2.5947\n",
            "Epoch 222/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8818 - mean_squared_error: 1.7899 - val_loss: 2.7822 - val_mean_squared_error: 2.6865\n",
            "Epoch 223/250\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 1.9288 - mean_squared_error: 1.8384 - val_loss: 2.7480 - val_mean_squared_error: 2.6560\n",
            "Epoch 224/250\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1.8792 - mean_squared_error: 1.7905 - val_loss: 2.6212 - val_mean_squared_error: 2.5332\n",
            "Epoch 225/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8735 - mean_squared_error: 1.7853 - val_loss: 2.6257 - val_mean_squared_error: 2.5386\n",
            "Epoch 226/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8806 - mean_squared_error: 1.7939 - val_loss: 2.6363 - val_mean_squared_error: 2.5508\n",
            "Epoch 227/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8629 - mean_squared_error: 1.7777 - val_loss: 2.5974 - val_mean_squared_error: 2.5101\n",
            "Epoch 228/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8714 - mean_squared_error: 1.7862 - val_loss: 2.6182 - val_mean_squared_error: 2.5324\n",
            "Epoch 229/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8496 - mean_squared_error: 1.7636 - val_loss: 2.6317 - val_mean_squared_error: 2.5454\n",
            "Epoch 230/250\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1.8612 - mean_squared_error: 1.7772 - val_loss: 2.9532 - val_mean_squared_error: 2.8667\n",
            "Epoch 231/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8898 - mean_squared_error: 1.8071 - val_loss: 2.6433 - val_mean_squared_error: 2.5591\n",
            "Epoch 232/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8792 - mean_squared_error: 1.7971 - val_loss: 2.6502 - val_mean_squared_error: 2.5715\n",
            "Epoch 233/250\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1.8705 - mean_squared_error: 1.7908 - val_loss: 2.5882 - val_mean_squared_error: 2.5058\n",
            "Epoch 234/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8562 - mean_squared_error: 1.7738 - val_loss: 2.6040 - val_mean_squared_error: 2.5223\n",
            "Epoch 235/250\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1.8653 - mean_squared_error: 1.7841 - val_loss: 2.6223 - val_mean_squared_error: 2.5406\n",
            "Epoch 236/250\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1.8738 - mean_squared_error: 1.7947 - val_loss: 2.6241 - val_mean_squared_error: 2.5445\n",
            "Epoch 237/250\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1.8422 - mean_squared_error: 1.7643 - val_loss: 2.5801 - val_mean_squared_error: 2.5030\n",
            "Epoch 238/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8569 - mean_squared_error: 1.7789 - val_loss: 2.6992 - val_mean_squared_error: 2.6203\n",
            "Epoch 239/250\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1.8490 - mean_squared_error: 1.7714 - val_loss: 2.5985 - val_mean_squared_error: 2.5216\n",
            "Epoch 240/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8374 - mean_squared_error: 1.7618 - val_loss: 2.6199 - val_mean_squared_error: 2.5448\n",
            "Epoch 241/250\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1.8649 - mean_squared_error: 1.7895 - val_loss: 2.6499 - val_mean_squared_error: 2.5751\n",
            "Epoch 242/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8393 - mean_squared_error: 1.7654 - val_loss: 2.5761 - val_mean_squared_error: 2.5043\n",
            "Epoch 243/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8662 - mean_squared_error: 1.7925 - val_loss: 2.6078 - val_mean_squared_error: 2.5352\n",
            "Epoch 244/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8751 - mean_squared_error: 1.8000 - val_loss: 2.5899 - val_mean_squared_error: 2.5129\n",
            "Epoch 245/250\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1.8809 - mean_squared_error: 1.8056 - val_loss: 2.6904 - val_mean_squared_error: 2.6136\n",
            "Epoch 246/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8923 - mean_squared_error: 1.8171 - val_loss: 2.5693 - val_mean_squared_error: 2.4885\n",
            "Epoch 247/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8645 - mean_squared_error: 1.7873 - val_loss: 2.5950 - val_mean_squared_error: 2.5206\n",
            "Epoch 248/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8550 - mean_squared_error: 1.7830 - val_loss: 2.5674 - val_mean_squared_error: 2.4905\n",
            "Epoch 249/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8556 - mean_squared_error: 1.7768 - val_loss: 2.5786 - val_mean_squared_error: 2.5041\n",
            "Epoch 250/250\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.8672 - mean_squared_error: 1.7972 - val_loss: 2.6063 - val_mean_squared_error: 2.5368\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 4ms/step - loss: 2.7802 - mean_squared_error: 2.7113\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.780172348022461, 2.7112674713134766]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T6qDH65q5Vzu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}